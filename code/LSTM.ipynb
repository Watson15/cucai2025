{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/sethmess/.local/lib/python3.13/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /home/sethmess/.local/lib/python3.13/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/sethmess/.local/lib/python3.13/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/sethmess/.local/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/sethmess/.local/lib/python3.13/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /home/sethmess/.local/lib/python3.13/site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/sethmess/.local/lib/python3.13/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/sethmess/.local/lib/python3.13/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/sethmess/.local/lib/python3.13/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/sethmess/.local/lib/python3.13/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/sethmess/.local/lib/python3.13/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/sethmess/.local/lib/python3.13/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/sethmess/.local/lib/python3.13/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/sethmess/.local/lib/python3.13/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/sethmess/.local/lib/python3.13/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/sethmess/.local/lib/python3.13/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/sethmess/.local/lib/python3.13/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/sethmess/.local/lib/python3.13/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/sethmess/.local/lib/python3.13/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/sethmess/.local/lib/python3.13/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3.13/site-packages (from torch) (69.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/sethmess/.local/lib/python3.13/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/sethmess/.local/lib/python3.13/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib64/python3.13/site-packages (from jinja2->torch) (2.1.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n",
      "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n",
      "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n",
      "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n",
      "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m More information is available at\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available and set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the LSTM Model for time-series prediction\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, dropout=0.0):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Define the LSTM layer (batch_first=True makes input shape: [batch, time_steps, features])\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, \n",
    "                            batch_first=True, dropout=dropout)\n",
    "        \n",
    "        # Fully connected layer for final output\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state and cell state (shape: [num_layers, batch, hidden_size])\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward pass through LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Take the output of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters (adjust these based on your dataset and experimentation)\n",
    "input_size = 10    # Number of weather features per time step (e.g., temperature, humidity, etc.)\n",
    "hidden_size = 50   # Number of hidden units (tune as needed)\n",
    "output_size = 1    # Predicting one value: GHI\n",
    "num_layers = 2     # Number of LSTM layers\n",
    "dropout = 0.2      # Optional dropout between LSTM layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for one time step:\n",
    "# [sky_layer1, sky_layer2, sky_layer3, sky_layer4, thunderstorm_code,\n",
    "#  rain_code, drizzle_code, snow_code, snow_showers_code, ice_pellets_code,\n",
    "#  fog_code, smoke_code]\n",
    "# Example vector might look like this\n",
    "time_step_input = [2, 0, 0, 0, 1, 3, 0, 0, 0, 0, 1, 0]\n",
    "\n",
    "# And if it was trained on the model below it one batch would be of dimention \n",
    "(batch_size, sequence_length, num_features) = (32, 5, 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMModel(\n",
      "  (lstm): LSTM(10, 50, num_layers=2, batch_first=True, dropout=0.2)\n",
      "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n",
      "Epoch [10/100], Loss: 0.9708\n",
      "Epoch [20/100], Loss: 1.0359\n",
      "Epoch [30/100], Loss: 1.1619\n",
      "Epoch [40/100], Loss: 1.5881\n",
      "Epoch [50/100], Loss: 0.9675\n",
      "Epoch [60/100], Loss: 0.7881\n",
      "Epoch [70/100], Loss: 1.1445\n",
      "Epoch [80/100], Loss: 0.7418\n",
      "Epoch [90/100], Loss: 1.4474\n",
      "Epoch [100/100], Loss: 0.7708\n"
     ]
    }
   ],
   "source": [
    "# Create the LSTM model instance and move it to the selected device\n",
    "model = LSTMModel(input_size, hidden_size, output_size, num_layers, dropout).to(device)\n",
    "print(model)\n",
    "\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error is common for regression tasks\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Sample Training Loop\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In practice, load your data here. For demonstration, we use random data:\n",
    "    # Inputs: shape (batch_size, sequence_length, input_size)\n",
    "    # Targets: shape (batch_size, output_size)\n",
    "    batch_size = 32\n",
    "    sequence_length = 5  # Number of time steps per sample eg this is 5 hours I think\n",
    "\n",
    "    # Replace random weights with a vector of features\n",
    "\n",
    "    \n",
    "    inputs = torch.randn(batch_size, sequence_length, input_size).to(device)\n",
    "    targets = torch.randn(batch_size, output_size).to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Output: [[0.07490139]]\n"
     ]
    }
   ],
   "source": [
    "# Inference example with new data\n",
    "\n",
    "# Use test data here\n",
    "\n",
    "model.eval()  # set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    # Example new_data: one sample, sequence length 5\n",
    "    new_data = torch.randn(1, sequence_length, input_size).to(device)\n",
    "    predicted_output = model(new_data)\n",
    "    print(\"Predicted Output:\", predicted_output.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Use somthing like this to preproccess the data to make sure it is in the same ranges\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m      4\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Use somthing like this to preproccess the data to make sure it is in the same ranges\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
